# -*- coding: utf-8 -*-
"""adrichQ1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16vHPvl6dbCOSAClu6j8gAfCWHMSU7NKR

Using TensorFlow Build a model that, given some subset of the feature columns (listed below), predict the chance of admission.

GRE score, TOEFL score, University Rating, SOP, LOR, CGPA, Research → Features
Chance of admit → Target val
"""

import tensorflow as tf 
from tensorflow import keras
import pandas as pd 
import numpy as np
import sklearn 
from sklearn.model_selection import train_test_split


data = pd.read_csv('Admission_Predict.csv')
data.drop('Serial No.', axis='columns', inplace=True)

df = pd.DataFrame(data)
df = df[df.columns[0:7]]
df.describe()

"""Now we need to normalize the data so eveything comes in the same format. For this we can use the maximum absolute scaling function"""



"""Applying the minimum and maximum scaling to keep everything in 0,1 range"""

def min_max_scaling(df):
    
    df_norm = df.copy()
   
    for column in df_norm.columns:
        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())
        
    return df_norm
    

df_normalized_results = min_max_scaling(df)
df_normalized_results

"""The next part should be to split the data between train and test """

X = data.drop(['Chance of Admit '], axis=1)
y = data['Chance of Admit ']
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.10, shuffle=False)

"""Now let's test the accuracy using different models"""

from sklearn.linear_model import LinearRegression

from sklearn.ensemble import RandomForestRegressor

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error


models = [['DecisionTree :',DecisionTreeRegressor()],
           ['Linear Regression :', LinearRegression()],
           ['RandomForest :',RandomForestRegressor()]]


for name,model in models:
    model = model
    model.fit(X_train,y_train)
    predictions = model.predict(X_test)
    print(predictions)
    print(name, (np.sqrt(mean_squared_error(y_test, predictions))))

"""Linear regression is better than others.

Many differnet models are used for this purpose and now  to NN for the sake of using Tensorflow v1.
"""

train, test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)
training_label = train.pop('Chance of Admit ')
test_label = test.pop('Chance of Admit ')

def build_model(dataset_length,hidden_size,learning_rate):
    model = keras.Sequential([
        keras.layers.Dense(hidden_size,activation=tf.nn.relu, input_shape = [dataset_length]),
        keras.layers.Dense(hidden_size, activation=tf.nn.relu),
        keras.layers.Dense(1)
    ])

    optimizer = tf.keras.optimizers.RMSprop(learning_rate)
    model.compile(loss='mean_squared_error',
        optimizer=optimizer,
        metrics=['mean_absolute_error', 'mean_squared_error'])
     
    hist = model.fit(train,training_label,validation_data = (test,test_label),verbose=0,epochs=30,batch_size = batch_size)
    loss,mean_abs_error,mean_squared_error = model.evaluate(test,test_label,verbose=0)

    
   
    
    print("Average mean absolute error for  testing data = {0:2.2f}%".format(mean_abs_error))
    print("Average mean squared error for test data = {0:2.2f}%".format(mean_squared_error))
    return model

if __name__ == "__main__":

    # parameters for building the model
    LAYER_SIZE = 256
    LEARNING_RATE = 0.0001
    NO_EPOCHS = 30
    BATCH_SIZE = 30
    K = 4
    model_params = (len(train.keys()),LAYER_SIZE,LEARNING_RATE)
    build_model(*model_params)

"""NOW Below is a second method in TF 1"""

import tensorflow.compat.v1 as tf 
tf.disable_v2_behavior()

def multilayer_perceptron(x, weights, biases, keep_prob):
    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])
    layer_1 = tf.nn.relu(layer_1)
    layer_1 = tf.nn.dropout(layer_1, keep_prob)
    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']
    return out_layer

    n_hidden_1 = 38
    n_input = train.shape[1]
    n_classes = test.shape[1]

    #we're using a random weight function defined by tensorflow
    weights = {
          'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1])),
          'out': tf.Variable(tf.random.normal([n_hidden_1, n_classes]))
          }

    biases = {
          'b1': tf.Variable(tf.random.normal([n_hidden_1])),
          'out': tf.Variable(tf.random.normal([n_classes]))
      }
      #placeholder replaced in tf v2 
    keep_prob = tf.compat.v1.placeholder("float")

    #Use any choice of optimizer

    optimizer = tf.train.AdamOptimizer(learning_rate=0.0003).minimize(cost)

    predictions = multilayer_perceptron(x, weights, biases, keep_prob)


    #Using Soft-Max loss function ; Can use other cost functions as well Mean-Sqaure-Func
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))

    training_epochs = 3000
    display_step = 1000

    #Increasr the batch-size basd on the size of the data, here it's very small
    batch_size = 64  

    x = tf.compat.v1.placeholder("float", [None, n_input])
    y = tf.compat.v1.placeholder("float", [None, n_classes])

    with tf.Session() as sess:
      sess.run(tf.global_variables_initializer())
    
    for epoch in range(training_epochs):
        avg_cost = 0.0
        total_batch = int(len(train) / batch_size)
        x_batches = np.array_split(train, total_batch)
        y_batches = np.array_split(train, total_batch)
        for i in range(total_batch):
            batch_x, batch_y = x_batches[i], y_batches[i]
            _, c = sess.run([self.optimizer, cost], 
                            feed_dict={
                                x: batch_x, 
                                y: batch_y, 
                                keep_prob: 0.8
                            })
            avg_cost += c / total_batch
        if epoch % display_step == 0:
            print("Epoch:", '%04d' % (epoch+1), "cost=", \
                "{:.9f}".format(avg_cost))
    print("Optimization Finished!")
    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
    print("Accuracy:", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))

